{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1455] The paging file is too small for this operation to complete. Error loading \"c:\\Users\\puthu\\anaconda3\\envs\\fva\\lib\\site-packages\\torch\\lib\\cusolverMg64_11.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n",
      "File \u001b[1;32mc:\\Users\\puthu\\anaconda3\\envs\\fva\\lib\\site-packages\\torch\\__init__.py:129\u001b[0m\n\u001b[0;32m    127\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    128\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"c:\\Users\\puthu\\anaconda3\\envs\\fva\\lib\\site-packages\\torch\\lib\\cusolverMg64_11.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy.io\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's load annotation and sample image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations\n",
    "annotations = scipy.io.loadmat('../data/cars_annos.mat')\n",
    "train_images_dir = '../data/cars_train/cars_train'  # Correct base directory\n",
    "\n",
    "# Function to display images\n",
    "def show_image(image_path, label):\n",
    "    image = Image.open(image_path)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display the first 2 images\n",
    "for i in range(2):\n",
    "    anno = annotations['annotations'][0][i]\n",
    "    img_name = anno[0][0]  # Get the image name with the directory\n",
    "    img_name = img_name.replace('car_ims/', '')  # Remove 'car_ims/' from the path\n",
    "\n",
    "    # Remove leading zero if present\n",
    "    if img_name.startswith('0'):\n",
    "        img_name = img_name[1:]\n",
    "\n",
    "    full_img_path = os.path.join(train_images_dir, img_name)\n",
    "    label = anno[5][0][0]\n",
    "    print(f\"Displaying image: {full_img_path}\")\n",
    "    show_image(full_img_path, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_max(path):\n",
    "\n",
    "    # Load annotations\n",
    "    annotations = scipy.io.loadmat(path)\n",
    "\n",
    "    # Function to display images\n",
    "    def show_image(image_path, label):\n",
    "        image = Image.open(image_path)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f'Label: {label}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    # Initialize the max image number\n",
    "    max_img_number = -1\n",
    "\n",
    "    # Iterate through all annotations to find the max image name\n",
    "    for anno in annotations['annotations'][0]:\n",
    "        img_name = anno[0][0]  # Get the image name with the directory\n",
    "        img_name_cleaned = img_name.replace('car_ims/', '')  # Remove 'car_ims/' from the path\n",
    "\n",
    "        # Extract the numerical part of the image name\n",
    "        img_number = int(img_name_cleaned.split('.')[0])\n",
    "        \n",
    "        # Compare and update the max image number\n",
    "        if img_number > max_img_number:\n",
    "            max_img_number = img_number\n",
    "\n",
    "    # Format the max image number with leading zeros\n",
    "    max_img_name = f\"{max_img_number:05d}.jpg\"\n",
    "\n",
    "    print(f\"The maximum image name is: {max_img_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_max('../data/cars_annos.mat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the max range is 16185 , and our train data does not contain that much image , let's remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations\n",
    "annotations = scipy.io.loadmat('../data/cars_annos.mat')\n",
    "train_images_dir = '../data/cars_train/cars_train'  # Correct base directory\n",
    "\n",
    "# Function to display images\n",
    "def show_image(image_path, label):\n",
    "    image = Image.open(image_path)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Define the maximum allowed image number\n",
    "max_allowed_img_number = 8144\n",
    "\n",
    "# Initialize list to hold updated annotations\n",
    "updated_annotations = []\n",
    "\n",
    "# Iterate through all annotations and filter out those with image names greater than max_allowed_img_number\n",
    "for anno in annotations['annotations'][0]:\n",
    "    img_name = anno[0][0]  # Get the image name with the directory\n",
    "    img_name_cleaned = img_name.replace('car_ims/', '')  # Remove 'car_ims/' from the path\n",
    "    \n",
    "    # Extract the numerical part of the image name\n",
    "    img_number = int(img_name_cleaned.split('.')[0])\n",
    "    \n",
    "    if img_number <= max_allowed_img_number:\n",
    "        updated_annotations.append(anno)\n",
    "\n",
    "# Convert the updated annotations back to a structured array\n",
    "annotations['annotations'] = np.array(updated_annotations, dtype=annotations['annotations'].dtype)\n",
    "\n",
    "# Save the updated annotations to a new mat file\n",
    "scipy.io.savemat('../data/cars_annos_updated.mat', annotations)\n",
    "\n",
    "# Display a message indicating the number of remaining images\n",
    "print(f\"Updated annotations to contain only images with names less than or equal to {max_allowed_img_number:05d}.jpg.\")\n",
    "print(f\"Total images after update: {len(updated_annotations)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_max('../data/cars_annos_updated.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load updated annotations\n",
    "annotations = scipy.io.loadmat('../data/cars_annos_updated.mat')\n",
    "\n",
    "# Custom dataset class\n",
    "class CarDataset(Dataset):\n",
    "    def __init__(self, annotations, img_dir, transform=None):\n",
    "        self.annotations = annotations['annotations'][0]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anno = self.annotations[idx]\n",
    "        img_name = anno[0][0].replace('car_ims/', '')\n",
    "\n",
    "        # Remove the leading zero if present\n",
    "        if img_name.startswith('0'):\n",
    "            img_name = img_name[1:]\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = torch.tensor(anno[5][0][0] - 1, dtype=torch.long)  # Get the class label and convert to LongTensor\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "img_dir = '../data/cars_train/cars_train'\n",
    "dataset = CarDataset(annotations, img_dir, transform=transform)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the model\n",
    "class VehicleClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VehicleClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "num_classes = len(scipy.io.loadmat('../data/cars_annos_updated.mat')['class_names'][0])\n",
    "model = VehicleClassifier(num_classes).to(device)  # Move model to the device\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Training loop with timing and early stopping\n",
    "num_epochs = 50\n",
    "patience = 10  # Number of epochs with no improvement after which training will be stopped\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to the device\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to the device\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_accuracy = correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Check early stopping condition\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(\"Saved best model\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve == patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "# Save the final model\n",
    "torch.save(model.state_dict(), 'final_model.pth')\n",
    "print(\"Saved final model\")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f'Total training time: {total_time / 60:.2f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import scipy.io\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load class names\n",
    "class_names = scipy.io.loadmat('../data/cars_annos_updated.mat')['class_names'][0]\n",
    "\n",
    "# Define the model class\n",
    "class VehicleClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VehicleClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path, model_class, num_classes):\n",
    "    model = model_class(num_classes)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Load the best model for inference\n",
    "num_classes = len(class_names)\n",
    "model = load_model('../model/final_model_epoch10_patience_2.pth', VehicleClassifier, num_classes)\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to predict class of an image\n",
    "def predict_image_class(image, model, transform):\n",
    "    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Move image to the device\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "# Load video\n",
    "video_path = '../data/traffic.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "predicted_classes = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Predict the class of the frame\n",
    "    predicted_class = predict_image_class(frame, model, transform)\n",
    "    class_label = class_names[predicted_class][0]\n",
    "    \n",
    "    # Append to predicted_classes\n",
    "    predicted_classes.append(class_label)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.putText(frame, f'{class_label}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Textual representation\n",
    "class_counts = defaultdict(int)\n",
    "for predicted_class in predicted_classes:\n",
    "    class_counts[predicted_class] += 1\n",
    "\n",
    "print(\"Predicted Class Counts:\")\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name}: {count}\")\n",
    "\n",
    "# Tabular representation\n",
    "df = pd.DataFrame(predicted_classes, columns=[\"Predicted Class\"])\n",
    "class_counts_df = df[\"Predicted Class\"].value_counts().reset_index()\n",
    "class_counts_df.columns = [\"Predicted Class\", \"Count\"]\n",
    "print(class_counts_df)\n",
    "\n",
    "# Graphical representation\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts_df.plot(kind='bar', x='Predicted Class', y='Count', legend=False)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Frequency of Predicted Classes')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets save the results to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import scipy.io\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load class names\n",
    "class_names = scipy.io.loadmat('../data/cars_annos_updated.mat')['class_names'][0]\n",
    "\n",
    "# Define the model class\n",
    "class VehicleClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VehicleClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path, model_class, num_classes):\n",
    "    model = model_class(num_classes)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Load the best model for inference\n",
    "num_classes = len(class_names)\n",
    "model = load_model('../model/final_model_epoch10_patience_2.pth', VehicleClassifier, num_classes)\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to predict class of an image\n",
    "def predict_image_class(image, model, transform):\n",
    "    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Move image to the device\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "# Load video\n",
    "video_path = '../data/traffic.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "frame_predictions = []\n",
    "frame_number = 0\n",
    "output_dir = 'output_frames'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Predict the class of the frame\n",
    "    predicted_class = predict_image_class(frame, model, transform)\n",
    "    class_label = class_names[predicted_class][0]\n",
    "    \n",
    "    # Append frame number and prediction to list\n",
    "    frame_predictions.append((frame_number, class_label))\n",
    "    \n",
    "    # Overlay the class label on the frame\n",
    "    cv2.putText(frame, f'{class_label}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "    # Save the frame with the prediction\n",
    "    output_path = os.path.join(output_dir, f'frame_{frame_number:04d}.png')\n",
    "    cv2.imwrite(output_path, frame)\n",
    "    \n",
    "    frame_number += 1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(frame_predictions, columns=[\"Frame Number\", \"Predicted Class\"])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"frame_predictions.csv\", index=False)\n",
    "\n",
    "# Display the saved frames in a grid\n",
    "def display_frames_grid(output_dir, num_frames=12):\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
    "    fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "\n",
    "    frame_files = sorted(os.listdir(output_dir))[:num_frames]\n",
    "    for ax, frame_file in zip(axes.flatten(), frame_files):\n",
    "        img = cv2.imread(os.path.join(output_dir, frame_file))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img_rgb)\n",
    "        ax.set_title(frame_file)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "display_frames_grid(output_dir, num_frames=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to label the dataset with color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "# Path to the dataset\n",
    "dataset_path = '../data/cars_train'\n",
    "image_folder = os.path.join(dataset_path, 'cars_train')\n",
    "label_file = os.path.join(dataset_path, 'color_labels.json')\n",
    "\n",
    "# Load existing labels if available\n",
    "if os.path.exists(label_file):\n",
    "    with open(label_file, 'r') as f:\n",
    "        color_labels = json.load(f)\n",
    "else:\n",
    "    color_labels = {}\n",
    "\n",
    "# Color options\n",
    "color_options = ['red', 'blue', 'green', 'black', 'white', 'yellow', 'gray', 'other']\n",
    "\n",
    "def label_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    cv2.imshow('Image', image)\n",
    "    print(f\"Label the color for the image: {image_path}\")\n",
    "    for i, color in enumerate(color_options):\n",
    "        print(f\"{i}: {color}\")\n",
    "    \n",
    "    key = cv2.waitKey(0)\n",
    "    if key >= 48 and key <= 48 + len(color_options) - 1:\n",
    "        return color_options[key - 48]\n",
    "    return 'other'\n",
    "\n",
    "# Label images\n",
    "for img_name in os.listdir(image_folder):\n",
    "    img_path = os.path.join(image_folder, img_name)\n",
    "    if img_name not in color_labels:\n",
    "        color = label_image(img_path)\n",
    "        color_labels[img_name] = color\n",
    "\n",
    "# Save labels\n",
    "with open(label_file, 'w') as f:\n",
    "    json.dump(color_labels, f)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from colorthief import ColorThief\n",
    "from PIL import Image\n",
    "\n",
    "# Path to the dataset\n",
    "dataset_path = '../data/cars_train'\n",
    "image_folder = os.path.join(dataset_path, 'cars_train')\n",
    "label_file = os.path.join(dataset_path, 'color_labels.json')\n",
    "\n",
    "# Load existing labels if available\n",
    "if os.path.exists(label_file):\n",
    "    with open(label_file, 'r') as f:\n",
    "        color_labels = json.load(f)\n",
    "else:\n",
    "    color_labels = {}\n",
    "\n",
    "# Color options\n",
    "color_options = ['red', 'blue', 'green', 'black', 'white', 'yellow', 'gray', 'other']\n",
    "\n",
    "# Function to map RGB to the closest color option\n",
    "def closest_color(rgb):\n",
    "    color_map = {\n",
    "        'red': (255, 0, 0),\n",
    "        'blue': (0, 0, 255),\n",
    "        'green': (0, 255, 0),\n",
    "        'black': (0, 0, 0),\n",
    "        'white': (255, 255, 255),\n",
    "        'yellow': (255, 255, 0),\n",
    "        'gray': (128, 128, 128),\n",
    "        'other': (0, 0, 0)  # Default\n",
    "    }\n",
    "    distances = {color: sum((component1 - component2) ** 2 for component1, component2 in zip(rgb, color_map[color])) for color in color_map}\n",
    "    return min(distances, key=distances.get)\n",
    "\n",
    "# Label images\n",
    "for img_name in os.listdir(image_folder):\n",
    "    if img_name not in color_labels:\n",
    "        img_path = os.path.join(image_folder, img_name)\n",
    "        color_thief = ColorThief(img_path)\n",
    "        dominant_color = color_thief.get_color(quality=1)\n",
    "        color = closest_color(dominant_color)\n",
    "        color_labels[img_name] = color\n",
    "\n",
    "# Save labels\n",
    "with open(label_file, 'w') as f:\n",
    "    json.dump(color_labels, f)\n",
    "\n",
    "print(\"Color labeling completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
